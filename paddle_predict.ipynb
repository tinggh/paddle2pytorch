{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffa0b3c5",
   "metadata": {},
   "source": [
    "# convert paddle ocr model to pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c8117d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copyright (c) 2020 PaddlePaddle Authors. All Rights Reserve.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#    http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import paddle\n",
    "from paddle import ParamAttr\n",
    "import paddle.nn as nn\n",
    "import paddle.nn.functional as F\n",
    "\n",
    "__all__ = [\"ResNet\"]\n",
    "\n",
    "\n",
    "class ConvBNLayer(nn.Layer):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size,\n",
    "            stride=1,\n",
    "            groups=1,\n",
    "            is_vd_mode=False,\n",
    "            act=None,\n",
    "            name=None, ):\n",
    "        super(ConvBNLayer, self).__init__()\n",
    "\n",
    "        self.is_vd_mode = is_vd_mode\n",
    "        self._pool2d_avg = nn.AvgPool2D(\n",
    "            kernel_size=stride, stride=stride, padding=0, ceil_mode=True)\n",
    "        self._conv = nn.Conv2D(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=1 if is_vd_mode else stride,\n",
    "            padding=(kernel_size - 1) // 2,\n",
    "            groups=groups,\n",
    "            weight_attr=ParamAttr(name=name + \"_weights\"),\n",
    "            bias_attr=False)\n",
    "        if name == \"conv1\":\n",
    "            bn_name = \"bn_\" + name\n",
    "        else:\n",
    "            bn_name = \"bn\" + name[3:]\n",
    "        self._batch_norm = nn.BatchNorm(\n",
    "            out_channels,\n",
    "            act=act,\n",
    "            param_attr=ParamAttr(name=bn_name + '_scale'),\n",
    "            bias_attr=ParamAttr(bn_name + '_offset'),\n",
    "            moving_mean_name=bn_name + '_mean',\n",
    "            moving_variance_name=bn_name + '_variance')\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        if self.is_vd_mode:\n",
    "            inputs = self._pool2d_avg(inputs)\n",
    "        y = self._conv(inputs)\n",
    "        y = self._batch_norm(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class BottleneckBlock(nn.Layer):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 stride,\n",
    "                 shortcut=True,\n",
    "                 if_first=False,\n",
    "                 name=None):\n",
    "        super(BottleneckBlock, self).__init__()\n",
    "\n",
    "        self.conv0 = ConvBNLayer(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=1,\n",
    "            act='relu',\n",
    "            name=name + \"_branch2a\")\n",
    "        self.conv1 = ConvBNLayer(\n",
    "            in_channels=out_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            act='relu',\n",
    "            name=name + \"_branch2b\")\n",
    "        self.conv2 = ConvBNLayer(\n",
    "            in_channels=out_channels,\n",
    "            out_channels=out_channels * 4,\n",
    "            kernel_size=1,\n",
    "            act=None,\n",
    "            name=name + \"_branch2c\")\n",
    "\n",
    "        if not shortcut:\n",
    "            self.short = ConvBNLayer(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels * 4,\n",
    "                kernel_size=1,\n",
    "                stride=stride,\n",
    "                is_vd_mode=not if_first and stride[0] != 1,\n",
    "                name=name + \"_branch1\")\n",
    "\n",
    "        self.shortcut = shortcut\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        y = self.conv0(inputs)\n",
    "\n",
    "        conv1 = self.conv1(y)\n",
    "        conv2 = self.conv2(conv1)\n",
    "\n",
    "        if self.shortcut:\n",
    "            short = inputs\n",
    "        else:\n",
    "            short = self.short(inputs)\n",
    "        y = paddle.add(x=short, y=conv2)\n",
    "        y = F.relu(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Layer):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 stride,\n",
    "                 shortcut=True,\n",
    "                 if_first=False,\n",
    "                 name=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.stride = stride\n",
    "        self.conv0 = ConvBNLayer(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            act='relu',\n",
    "            name=name + \"_branch2a\")\n",
    "        self.conv1 = ConvBNLayer(\n",
    "            in_channels=out_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=3,\n",
    "            act=None,\n",
    "            name=name + \"_branch2b\")\n",
    "\n",
    "        if not shortcut:\n",
    "            self.short = ConvBNLayer(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=1,\n",
    "                stride=stride,\n",
    "                is_vd_mode=not if_first and stride[0] != 1,\n",
    "                name=name + \"_branch1\")\n",
    "\n",
    "        self.shortcut = shortcut\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        y = self.conv0(inputs)\n",
    "        conv1 = self.conv1(y)\n",
    "\n",
    "        if self.shortcut:\n",
    "            short = inputs\n",
    "        else:\n",
    "            short = self.short(inputs)\n",
    "        y = paddle.add(x=short, y=conv1)\n",
    "        y = F.relu(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class ResNet(nn.Layer):\n",
    "    def __init__(self, in_channels=3, layers=50, **kwargs):\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        self.layers = layers\n",
    "        supported_layers = [18, 34, 50, 101, 152, 200]\n",
    "        assert layers in supported_layers, \\\n",
    "            \"supported layers are {} but input layer is {}\".format(\n",
    "                supported_layers, layers)\n",
    "\n",
    "        if layers == 18:\n",
    "            depth = [2, 2, 2, 2]\n",
    "        elif layers == 34 or layers == 50:\n",
    "            depth = [3, 4, 6, 3]\n",
    "        elif layers == 101:\n",
    "            depth = [3, 4, 23, 3]\n",
    "        elif layers == 152:\n",
    "            depth = [3, 8, 36, 3]\n",
    "        elif layers == 200:\n",
    "            depth = [3, 12, 48, 3]\n",
    "        num_channels = [64, 256, 512,\n",
    "                        1024] if layers >= 50 else [64, 64, 128, 256]\n",
    "        num_filters = [64, 128, 256, 512]\n",
    "\n",
    "        self.conv1_1 = ConvBNLayer(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=32,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            act='relu',\n",
    "            name=\"conv1_1\")\n",
    "        self.conv1_2 = ConvBNLayer(\n",
    "            in_channels=32,\n",
    "            out_channels=32,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            act='relu',\n",
    "            name=\"conv1_2\")\n",
    "        self.conv1_3 = ConvBNLayer(\n",
    "            in_channels=32,\n",
    "            out_channels=64,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            act='relu',\n",
    "            name=\"conv1_3\")\n",
    "        self.pool2d_max = nn.MaxPool2D(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.block_list = []\n",
    "        if layers >= 50:\n",
    "            for block in range(len(depth)):\n",
    "                shortcut = False\n",
    "                for i in range(depth[block]):\n",
    "                    if layers in [101, 152, 200] and block == 2:\n",
    "                        if i == 0:\n",
    "                            conv_name = \"res\" + str(block + 2) + \"a\"\n",
    "                        else:\n",
    "                            conv_name = \"res\" + str(block + 2) + \"b\" + str(i)\n",
    "                    else:\n",
    "                        conv_name = \"res\" + str(block + 2) + chr(97 + i)\n",
    "\n",
    "                    if i == 0 and block != 0:\n",
    "                        stride = (2, 1)\n",
    "                    else:\n",
    "                        stride = (1, 1)\n",
    "                    bottleneck_block = self.add_sublayer(\n",
    "                        'bb_%d_%d' % (block, i),\n",
    "                        BottleneckBlock(\n",
    "                            in_channels=num_channels[block]\n",
    "                            if i == 0 else num_filters[block] * 4,\n",
    "                            out_channels=num_filters[block],\n",
    "                            stride=stride,\n",
    "                            shortcut=shortcut,\n",
    "                            if_first=block == i == 0,\n",
    "                            name=conv_name))\n",
    "                    shortcut = True\n",
    "                    self.block_list.append(bottleneck_block)\n",
    "                self.out_channels = num_filters[block] * 4\n",
    "        else:\n",
    "            for block in range(len(depth)):\n",
    "                shortcut = False\n",
    "                for i in range(depth[block]):\n",
    "                    conv_name = \"res\" + str(block + 2) + chr(97 + i)\n",
    "                    if i == 0 and block != 0:\n",
    "                        stride = (2, 1)\n",
    "                    else:\n",
    "                        stride = (1, 1)\n",
    "\n",
    "                    basic_block = self.add_sublayer(\n",
    "                        'bb_%d_%d' % (block, i),\n",
    "                        BasicBlock(\n",
    "                            in_channels=num_channels[block]\n",
    "                            if i == 0 else num_filters[block],\n",
    "                            out_channels=num_filters[block],\n",
    "                            stride=stride,\n",
    "                            shortcut=shortcut,\n",
    "                            if_first=block == i == 0,\n",
    "                            name=conv_name))\n",
    "                    shortcut = True\n",
    "                    self.block_list.append(basic_block)\n",
    "                self.out_channels = num_filters[block]\n",
    "        self.out_pool = nn.MaxPool2D(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        y = self.conv1_1(inputs)\n",
    "        y = self.conv1_2(y)\n",
    "        y = self.conv1_3(y)\n",
    "        y = self.pool2d_max(y)\n",
    "        for block in self.block_list:\n",
    "            y = block(y)\n",
    "        y = self.out_pool(y)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b01e7cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddle import nn\n",
    "\n",
    "class Im2Seq(nn.Layer):\n",
    "    def __init__(self, in_channels, **kwargs):\n",
    "        super().__init__()\n",
    "        self.out_channels = in_channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        assert H == 1\n",
    "        x = x.squeeze(axis=2)\n",
    "        x = x.transpose([0, 2, 1])  # (NTC)(batch, width, channels)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EncoderWithRNN(nn.Layer):\n",
    "    def __init__(self, in_channels, hidden_size):\n",
    "        super(EncoderWithRNN, self).__init__()\n",
    "        self.out_channels = hidden_size * 2\n",
    "        self.lstm = nn.LSTM(\n",
    "            in_channels, hidden_size, direction='bidirectional', num_layers=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        return x\n",
    "\n",
    "class SequenceEncoder(nn.Layer):\n",
    "    def __init__(self, in_channels, hidden_size=48, **kwargs):\n",
    "        super(SequenceEncoder, self).__init__()\n",
    "        self.encoder_reshape = Im2Seq(in_channels)\n",
    "        self.out_channels = self.encoder_reshape.out_channels\n",
    "\n",
    "        self.encoder = EncoderWithRNN(\n",
    "            self.encoder_reshape.out_channels, hidden_size)\n",
    "        self.out_channels = self.encoder.out_channels\n",
    "        self.only_reshape = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder_reshape(x)\n",
    "        x = self.encoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeb61f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import paddle\n",
    "from paddle import ParamAttr, nn\n",
    "from paddle.nn import functional as F\n",
    "\n",
    "\n",
    "def get_para_bias_attr(l2_decay, k, name):\n",
    "    regularizer = paddle.regularizer.L2Decay(l2_decay)\n",
    "    stdv = 1.0 / math.sqrt(k * 1.0)\n",
    "    initializer = nn.initializer.Uniform(-stdv, stdv)\n",
    "    weight_attr = ParamAttr(\n",
    "        regularizer=regularizer, initializer=initializer, name=name + \"_w_attr\")\n",
    "    bias_attr = ParamAttr(\n",
    "        regularizer=regularizer, initializer=initializer, name=name + \"_b_attr\")\n",
    "    return [weight_attr, bias_attr]\n",
    "\n",
    "\n",
    "class CTCHead(nn.Layer):\n",
    "    def __init__(self, in_channels, out_channels, fc_decay=0.0004, **kwargs):\n",
    "        super(CTCHead, self).__init__()\n",
    "        weight_attr, bias_attr = get_para_bias_attr(\n",
    "            l2_decay=fc_decay, k=in_channels, name='ctc_fc')\n",
    "        self.fc = nn.Linear(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            weight_attr=weight_attr,\n",
    "            bias_attr=bias_attr,\n",
    "            name='ctc_fc')\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "    def forward(self, x, labels=None):\n",
    "        predicts = self.fc(x)\n",
    "        if not self.training:\n",
    "            predicts = F.softmax(predicts, axis=2)\n",
    "        return predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f74f412a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaddleRecModel(nn.Layer):\n",
    "    def __init__(self, in_channels=1):\n",
    "        super(PaddleRecModel, self).__init__()\n",
    "        self.backbone = ResNet(in_channels=in_channels, layers=34)\n",
    "        self.neck = SequenceEncoder(self.backbone.out_channels, hidden_size=256)\n",
    "        self.head = CTCHead(self.neck.out_channels, 6625)\n",
    "\n",
    "    def forward(self, x, data=None):\n",
    "        x = self.backbone(x)\n",
    "        x = self.neck(x)\n",
    "        x = self.head(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "002abd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabets_path = \"../ppocr_keys_v1.txt\"\n",
    "\n",
    "with open(alphabets_path, \"rb\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "char_list = [char.decode(\"utf-8\").strip(\"\\n\").strip(\"\\r\\n\") for char in lines]\n",
    "alphabets = [\"blank\"] + char_list + [\" \"]\n",
    "# print(alphabets)\n",
    "char_dict = {}\n",
    "for i, char in enumerate(alphabets):\n",
    "    char_dict[char] = i\n",
    "\n",
    "def decode(preds, raw=False):\n",
    "    if isinstance(preds, paddle.Tensor):\n",
    "        preds = preds.numpy()\n",
    "    text_index = preds.argmax(axis=2)\n",
    "    text_prob = preds.max(axis=2)\n",
    "    \n",
    "    result_list = []\n",
    "    ignored_tokens = [\"0\"]\n",
    "    batch_size = len(text_index)\n",
    "    for batch_idx in range(batch_size):\n",
    "        char_list = []\n",
    "        conf_list = []\n",
    "        for idx in range(len(text_index[batch_idx])):\n",
    "            if text_index[batch_idx][idx] in ignored_tokens:\n",
    "                continue\n",
    "            \n",
    "            if idx > 0 and text_index[batch_idx][idx - 1] == text_index[\n",
    "                    batch_idx][idx]:\n",
    "                continue\n",
    "            char_list.append(char_dict[int(text_index[batch_idx][\n",
    "                idx])])\n",
    "            if text_prob is not None:\n",
    "                conf_list.append(text_prob[batch_idx][idx])\n",
    "            else:\n",
    "                conf_list.append(1)\n",
    "        text = ''.join(char_list)\n",
    "        result_list.append((text, np.mean(conf_list)))\n",
    "    return result_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ef34f01",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "parameter name [conv1_1_weights] have be been used. In dygraph mode, the name of parameter can't be same.Please check the parameter attr value passed to self.create_parameter or constructor of dygraph Layers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4328fcb1fb35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPaddleRecModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mcheckpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../ch_ppocr_server_v2.0_rec_pre/best_accuracy\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpara_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoints\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".pdparams\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-1dea3380d90e>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPaddleRecModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m34\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequenceEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCTCHead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneck\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6625\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-171a10923526>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, layers, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mact\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m             name=\"conv1_1\")\n\u001b[0m\u001b[1;32m    207\u001b[0m         self.conv1_2 = ConvBNLayer(\n\u001b[1;32m    208\u001b[0m             \u001b[0min_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-171a10923526>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, groups, is_vd_mode, act, name)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mweight_attr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mParamAttr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_weights\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             bias_attr=False)\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"conv1\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mbn_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"bn_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/miniconda3/envs/paddle_env/lib/python3.6/site-packages/paddle/nn/layer/conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, padding_mode, weight_attr, bias_attr, data_format)\u001b[0m\n\u001b[1;32m    644\u001b[0m             \u001b[0mweight_attr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_attr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m             \u001b[0mbias_attr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias_attr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m             data_format=data_format)\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/miniconda3/envs/paddle_env/lib/python3.6/site-packages/paddle/nn/layer/conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, transposed, dims, stride, padding, padding_mode, output_padding, dilation, groups, weight_attr, bias_attr, data_format)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilter_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mattr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param_attr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             default_initializer=_get_default_param_initializer())\n\u001b[0m\u001b[1;32m    136\u001b[0m         self.bias = self.create_parameter(\n\u001b[1;32m    137\u001b[0m             attr=self._bias_attr, shape=[self._out_channels], is_bias=True)\n",
      "\u001b[0;32m~/Documents/Work/miniconda3/envs/paddle_env/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36mcreate_parameter\u001b[0;34m(self, shape, attr, dtype, is_bias, default_initializer)\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0mtemp_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         return self._helper.create_parameter(temp_attr, shape, dtype, is_bias,\n\u001b[0;32m--> 412\u001b[0;31m                                              default_initializer)\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     @deprecated(\n",
      "\u001b[0;32m~/Documents/Work/miniconda3/envs/paddle_env/lib/python3.6/site-packages/paddle/fluid/layer_helper_base.py\u001b[0m in \u001b[0;36mcreate_parameter\u001b[0;34m(self, attr, shape, dtype, is_bias, default_initializer, stop_gradient, type)\u001b[0m\n\u001b[1;32m    366\u001b[0m                     \u001b[0;34m\"In dygraph mode, the name of parameter can't be same.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m                     \u001b[0;34m\"Please check the parameter attr value passed to self.create_parameter or \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m                     \"constructor of dygraph Layers\".format(attr.name))\n\u001b[0m\u001b[1;32m    369\u001b[0m             return self.main_program.global_block().create_parameter(\n\u001b[1;32m    370\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: parameter name [conv1_1_weights] have be been used. In dygraph mode, the name of parameter can't be same.Please check the parameter attr value passed to self.create_parameter or constructor of dygraph Layers"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "import os\n",
    "\n",
    "model = PaddleRecModel(in_channels=3)\n",
    "checkpoints = \"../ch_ppocr_server_v2.0_rec_pre/best_accuracy\"\n",
    "para_dict = paddle.load(checkpoints + \".pdparams\")\n",
    "opti_dict = paddle.load(checkpoints + \".pdopt\")\n",
    "\n",
    "model.set_state_dict(para_dict)\n",
    "model.eval()\n",
    "\n",
    "def predict(model, img):\n",
    "    h, w = img.shape[:2]\n",
    "    rh = 32\n",
    "    rw = math.ceil(32 / h * w)\n",
    "    img = cv2.resize(img, (rw, rh))\n",
    "    img = img.astype(\"float32\").transpose((2, 0, 1)) / 255\n",
    "    img -= 0.5\n",
    "    img /= 0.5\n",
    "    inp = img[np.newaxis, :]\n",
    "    inp = paddle.to_tensor(inp)\n",
    "    preds = model(inp)\n",
    "    print(preds.shape)\n",
    "    preds = F.softmax(preds, dim=2)\n",
    "    result_list = decode(preds, raw=False)\n",
    "    return result_list\n",
    "\n",
    "\n",
    "data_dir = \"./patches/\"\n",
    "for n in os.listdir(data_dir)[:10]:\n",
    "    print(n)\n",
    "    img = cv2.imread(data_dir + n)\n",
    "    plt.imshow(img[:, :, ::-1])\n",
    "    plt.show()\n",
    "    result_list = predict(net, img)\n",
    "    print(result_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
